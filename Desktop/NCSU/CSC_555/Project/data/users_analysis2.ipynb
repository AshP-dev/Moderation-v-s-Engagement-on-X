{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze tweet authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>lang</th>\n",
       "      <th>tweet_type</th>\n",
       "      <th>source</th>\n",
       "      <th>source_link</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>linked_tweet</th>\n",
       "      <th>linked_user</th>\n",
       "      <th>sensitive</th>\n",
       "      <th>access</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>870166174914555904</td>\n",
       "      <td>730634191583449088</td>\n",
       "      <td>2017-06-01 06:32:37</td>\n",
       "      <td>en</td>\n",
       "      <td>reply</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>http://twitter.com/download/iphone</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.701644e+17</td>\n",
       "      <td>8.627841e+17</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-06-01 06:32:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>870137999513747458</td>\n",
       "      <td>4870875423</td>\n",
       "      <td>2017-06-01 04:40:40</td>\n",
       "      <td>tr</td>\n",
       "      <td>quote</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>http://twitter.com/download/iphone</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.701354e+17</td>\n",
       "      <td>1.901715e+08</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-06-01 06:33:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>870166317504114688</td>\n",
       "      <td>829734079348273152</td>\n",
       "      <td>2017-06-01 06:33:11</td>\n",
       "      <td>tr</td>\n",
       "      <td>retweet</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>http://twitter.com/download/android</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.701380e+17</td>\n",
       "      <td>4.870875e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-06-01 06:33:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>870135387091595264</td>\n",
       "      <td>190171522</td>\n",
       "      <td>2017-06-01 04:30:17</td>\n",
       "      <td>tr</td>\n",
       "      <td>tweet</td>\n",
       "      <td>Hootsuite</td>\n",
       "      <td>http://www.hootsuite.com</td>\n",
       "      <td>32</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-06-01 06:33:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>870166745323114497</td>\n",
       "      <td>381994185</td>\n",
       "      <td>2017-06-01 06:34:53</td>\n",
       "      <td>tr</td>\n",
       "      <td>tweet</td>\n",
       "      <td>GundeTape</td>\n",
       "      <td>http://www.gundetape.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-06-01 06:34:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id           author_id           created_at lang  \\\n",
       "0  870166174914555904  730634191583449088  2017-06-01 06:32:37   en   \n",
       "1  870137999513747458          4870875423  2017-06-01 04:40:40   tr   \n",
       "2  870166317504114688  829734079348273152  2017-06-01 06:33:11   tr   \n",
       "3  870135387091595264           190171522  2017-06-01 04:30:17   tr   \n",
       "4  870166745323114497           381994185  2017-06-01 06:34:53   tr   \n",
       "\n",
       "  tweet_type               source                          source_link  \\\n",
       "0      reply   Twitter for iPhone   http://twitter.com/download/iphone   \n",
       "1      quote   Twitter for iPhone   http://twitter.com/download/iphone   \n",
       "2    retweet  Twitter for Android  http://twitter.com/download/android   \n",
       "3      tweet            Hootsuite             http://www.hootsuite.com   \n",
       "4      tweet            GundeTape             http://www.gundetape.com   \n",
       "\n",
       "   retweet_count  favorite_count  quote_count  reply_count  linked_tweet  \\\n",
       "0              0               0          NaN          NaN  8.701644e+17   \n",
       "1              5               0          NaN          NaN  8.701354e+17   \n",
       "2              0               0          NaN          NaN  8.701380e+17   \n",
       "3             32              19          NaN          NaN           NaN   \n",
       "4              0               0          NaN          NaN           NaN   \n",
       "\n",
       "    linked_user  sensitive               access  \n",
       "0  8.627841e+17      False  2017-06-01 06:32:37  \n",
       "1  1.901715e+08      False  2017-06-01 06:33:11  \n",
       "2  4.870875e+09      False  2017-06-01 06:33:11  \n",
       "3           NaN      False  2017-06-01 06:33:11  \n",
       "4           NaN      False  2017-06-01 06:34:53  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'write-folder/tweet_metadata.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect user ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[92460378,\n",
       " 954124423,\n",
       " 455264233,\n",
       " 526110917,\n",
       " 248829087,\n",
       " 3244921294,\n",
       " 37020028,\n",
       " 487834443,\n",
       " 4573876514,\n",
       " 214544700,\n",
       " 420542453,\n",
       " 2159335132,\n",
       " 478170193,\n",
       " 305655577,\n",
       " 838018569732501508,\n",
       " 273648929,\n",
       " 3735364760,\n",
       " 760497714652151808,\n",
       " 724984265994285056,\n",
       " 2167525794,\n",
       " 482838365,\n",
       " 854782095289397252,\n",
       " 86665649,\n",
       " 3709329729,\n",
       " 813914393788481540]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_counts = data['author_id'].value_counts()\n",
    "\n",
    "# print(author_counts.head(int(len(author_counts) * 0.10)))   # prints top 10% of author_counts (should be 37)\n",
    "\n",
    "top_authors = list(author_counts.head(25).index)  # top 25 authors\n",
    "top_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author_id\n",
       "92460378              413\n",
       "954124423             367\n",
       "455264233             236\n",
       "526110917             224\n",
       "248829087             164\n",
       "                     ... \n",
       "852535411046002688      1\n",
       "91325511                1\n",
       "492707698               1\n",
       "3171860673              1\n",
       "829611235               1\n",
       "Name: count, Length: 10527, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_counts = data['author_id'].value_counts()\n",
    "author_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique_authors_ids = data['author_id'].unique()\n",
    "#unique_authors_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect date of tweet withheld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                author_id          created_at\n",
      "0                   68093 2017-06-11 11:14:50\n",
      "1                  612473 2017-06-02 20:57:43\n",
      "2                  759251 2017-06-02 10:40:53\n",
      "3                  767800 2017-06-12 17:42:02\n",
      "4                  807095 2017-06-14 13:42:06\n",
      "...                   ...                 ...\n",
      "10522  987394916719431680 2018-05-02 20:03:07\n",
      "10523  987748224437030917 2018-05-02 17:10:28\n",
      "10524  987752531009916929 2018-05-02 18:04:22\n",
      "10525  990276638997991424 2018-05-02 20:36:04\n",
      "10526  991369146976931840 2018-05-02 22:26:29\n",
      "\n",
      "[10527 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Ensure the 'created_at' column is in datetime format\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "\n",
    "# Group by 'author_id' and get the earliest date in 'created_at' column\n",
    "earliest_dates = data.groupby('author_id')['created_at'].min().reset_index()\n",
    "\n",
    "# Display the earliest dates for each author_id\n",
    "print(earliest_dates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               author_id          created_at\n",
      "474             37020028 2015-02-26 22:38:28\n",
      "891             86665649 2017-05-31 16:07:03\n",
      "932             92460378 2017-04-21 16:43:08\n",
      "1521           214544700 2017-05-31 23:08:42\n",
      "1691           248829087 2017-05-31 12:06:21\n",
      "1819           273648929 2017-06-01 07:35:48\n",
      "1975           305655577 2017-06-01 16:30:10\n",
      "2448           420542453 2017-05-29 12:56:54\n",
      "2566           455264233 2017-03-18 16:30:25\n",
      "2640           478170193 2017-05-30 23:46:40\n",
      "2656           482838365 2017-05-29 18:01:15\n",
      "2673           487834443 2017-05-31 11:22:28\n",
      "2774           526110917 2017-05-30 23:32:47\n",
      "3526           954124423 2015-09-10 19:51:45\n",
      "4412          2159335132 2016-02-20 13:43:03\n",
      "4431          2167525794 2017-06-03 00:59:12\n",
      "6167          3244921294 2017-03-28 09:51:07\n",
      "6542          3709329729 2017-05-31 23:17:37\n",
      "6551          3735364760 2017-06-07 04:07:16\n",
      "6869          4573876514 2017-03-11 18:39:23\n",
      "7401  724984265994285056 2017-06-02 02:26:10\n",
      "7914  760497714652151808 2017-05-31 21:02:34\n",
      "8856  813914393788481540 2017-05-15 12:32:17\n",
      "9408  838018569732501508 2017-05-31 13:34:32\n",
      "9752  854782095289397252 2017-06-01 17:35:18\n"
     ]
    }
   ],
   "source": [
    "filtered_earliest_dates = earliest_dates[earliest_dates['author_id'].isin(top_authors)] \n",
    "print(filtered_earliest_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{37020028: '2015-02-26 Feb:02:1425008308',\n",
       " 86665649: '2017-05-31 May:05:1496261223',\n",
       " 92460378: '2017-04-21 Apr:04:1492807388',\n",
       " 214544700: '2017-05-31 May:05:1496286522',\n",
       " 248829087: '2017-05-31 May:05:1496246781',\n",
       " 273648929: '2017-06-01 Jun:06:1496316948',\n",
       " 305655577: '2017-06-01 Jun:06:1496349010',\n",
       " 420542453: '2017-05-29 May:05:1496077014',\n",
       " 455264233: '2017-03-18 Mar:03:1489869025',\n",
       " 478170193: '2017-05-30 May:05:1496202400',\n",
       " 482838365: '2017-05-29 May:05:1496095275',\n",
       " 487834443: '2017-05-31 May:05:1496244148',\n",
       " 526110917: '2017-05-30 May:05:1496201567',\n",
       " 954124423: '2015-09-10 Sep:09:1441929105',\n",
       " 2159335132: '2016-02-20 Feb:02:1455993783',\n",
       " 2167525794: '2017-06-03 Jun:06:1496465952',\n",
       " 3244921294: '2017-03-28 Mar:03:1490709067',\n",
       " 3709329729: '2017-05-31 May:05:1496287057',\n",
       " 3735364760: '2017-06-07 Jun:06:1496822836',\n",
       " 4573876514: '2017-03-11 Mar:03:1489275563',\n",
       " 724984265994285056: '2017-06-02 Jun:06:1496384770',\n",
       " 760497714652151808: '2017-05-31 May:05:1496278954',\n",
       " 813914393788481540: '2017-05-15 May:05:1494865937',\n",
       " 838018569732501508: '2017-05-31 May:05:1496252072',\n",
       " 854782095289397252: '2017-06-01 Jun:06:1496352918'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict = filtered_earliest_dates.set_index('author_id')['created_at'].dt.strftime('%Y-%m-%d %h:%m:%s').to_dict()\n",
    "\n",
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"37020028\": \"2015-02-26 Feb:02:1425008308\",\n",
      "    \"86665649\": \"2017-05-31 May:05:1496261223\",\n",
      "    \"92460378\": \"2017-04-21 Apr:04:1492807388\",\n",
      "    \"214544700\": \"2017-05-31 May:05:1496286522\",\n",
      "    \"248829087\": \"2017-05-31 May:05:1496246781\",\n",
      "    \"273648929\": \"2017-06-01 Jun:06:1496316948\",\n",
      "    \"305655577\": \"2017-06-01 Jun:06:1496349010\",\n",
      "    \"420542453\": \"2017-05-29 May:05:1496077014\",\n",
      "    \"455264233\": \"2017-03-18 Mar:03:1489869025\",\n",
      "    \"478170193\": \"2017-05-30 May:05:1496202400\",\n",
      "    \"482838365\": \"2017-05-29 May:05:1496095275\",\n",
      "    \"487834443\": \"2017-05-31 May:05:1496244148\",\n",
      "    \"526110917\": \"2017-05-30 May:05:1496201567\",\n",
      "    \"954124423\": \"2015-09-10 Sep:09:1441929105\",\n",
      "    \"2159335132\": \"2016-02-20 Feb:02:1455993783\",\n",
      "    \"2167525794\": \"2017-06-03 Jun:06:1496465952\",\n",
      "    \"3244921294\": \"2017-03-28 Mar:03:1490709067\",\n",
      "    \"3709329729\": \"2017-05-31 May:05:1496287057\",\n",
      "    \"3735364760\": \"2017-06-07 Jun:06:1496822836\",\n",
      "    \"4573876514\": \"2017-03-11 Mar:03:1489275563\",\n",
      "    \"724984265994285056\": \"2017-06-02 Jun:06:1496384770\",\n",
      "    \"760497714652151808\": \"2017-05-31 May:05:1496278954\",\n",
      "    \"813914393788481540\": \"2017-05-15 May:05:1494865937\",\n",
      "    \"838018569732501508\": \"2017-05-31 May:05:1496252072\",\n",
      "    \"854782095289397252\": \"2017-06-01 Jun:06:1496352918\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json_data = json.dumps(result_dict, indent=4)\n",
    "\n",
    "print(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go through raw data (what we ran the 1-mining.py script on) to see if user activity declined before and after the date they had a tweet withheld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'withholding_info.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m withholding_info_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwithholding_info.json\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Path to the JSON file with author withholding info\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Load withholding dates per author\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwithholding_info_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     12\u001b[0m     withholding_dates \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28mstr\u001b[39m(author_id): datetime\u001b[38;5;241m.\u001b[39mstrptime(date, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m author_id, date \u001b[38;5;129;01min\u001b[39;00m json\u001b[38;5;241m.\u001b[39mload(f)\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m     15\u001b[0m     }\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Initialize counts\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'withholding_info.json'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import bz2\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Paths\n",
    "data_folder = 'C:\\\\Users\\\\ajayc\\\\Downloads\\\\censored-tweets-raw'  # Path to the folder with .bz2 files\n",
    "withholding_info_file = 'withholding_info.json'  # Path to the JSON file with author withholding info\n",
    "\n",
    "# Load withholding dates per author\n",
    "with open(withholding_info_file, 'r') as f:\n",
    "    withholding_dates = {\n",
    "        str(author_id): datetime.strptime(date, \"%Y-%m-%d %H:%M:%S\")\n",
    "        for author_id, date in json.load(f).items()\n",
    "    }\n",
    "\n",
    "# Initialize counts\n",
    "tweet_counts = {author_id: {'before': 0, 'after': 0} for author_id in withholding_dates}\n",
    "skipped_tweets = 0  # Counter for skipped tweets (for debugging)\n",
    "\n",
    "def parse_tweet_line(line, tweet_counts):\n",
    "    global skipped_tweets\n",
    "    try:\n",
    "        tweet = json.loads(line)\n",
    "    except json.JSONDecodeError:\n",
    "        skipped_tweets += 1\n",
    "        return\n",
    "\n",
    "    # Access author ID and tweet creation date\n",
    "    author_id = str(tweet.get('user', {}).get('id_str'))\n",
    "    created_at = tweet.get('created_at')\n",
    "\n",
    "    if not author_id or author_id not in withholding_dates or not created_at:\n",
    "        skipped_tweets += 1\n",
    "        return\n",
    "\n",
    "    # Convert tweet timestamp to datetime\n",
    "    tweet_date = datetime.strptime(created_at, \"%a %b %d %H:%M:%S +0000 %Y\")\n",
    "\n",
    "    # Compare tweet date with withholding date\n",
    "    if tweet_date < withholding_dates[author_id]:    # should we do <= ?\n",
    "        tweet_counts[author_id]['before'] += 1\n",
    "    else:\n",
    "        tweet_counts[author_id]['after'] += 1\n",
    "\n",
    "def process_file(file_path, tweet_counts):\n",
    "    with bz2.open(file_path, 'rt') as f:\n",
    "        for line in f:\n",
    "            parse_tweet_line(line, tweet_counts)\n",
    "\n",
    "def main():\n",
    "    # Iterate over all .bz2 files in the directory\n",
    "    for root, _, files in os.walk(data_folder):\n",
    "        for file in files:\n",
    "            if file.endswith('.bz2'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                process_file(file_path, tweet_counts)\n",
    "\n",
    "    # Output the results and skipped tweet count\n",
    "    for author_id, counts in tweet_counts.items():\n",
    "        print(f\"Author {author_id}: {counts['before']} tweets before, {counts['after']} tweets after withholding date.\")\n",
    "    print(f\"Skipped tweets (due to errors or missing data): {skipped_tweets}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To add to existing json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import os\n",
    "\n",
    "# def append_json_lines_to_existing(folder_path, existing_file_path):\n",
    "#     # Open the existing file in append mode\n",
    "#     with open(existing_file_path, 'a') as existing_file:\n",
    "        \n",
    "#         # Process each JSON file in the specified folder\n",
    "#         for filename in os.listdir(folder_path):\n",
    "#             file_path = os.path.join(folder_path, filename)\n",
    "            \n",
    "#             # Ensure we're only working with JSON files\n",
    "#             if filename.endswith(\".json\"):\n",
    "#                 with open(file_path, 'r') as json_file:\n",
    "#                     # Read each line in the current file and append it to the existing file\n",
    "#                     for line in json_file:\n",
    "#                         # Append line by line to handle newline-delimited JSON\n",
    "#                         existing_file.write(line)\n",
    "\n",
    "# # Usage example:\n",
    "# folder_path = 'C:\\\\Users\\\\ajayc\\\\Downloads\\\\Output'\n",
    "# existing_file_path = 'output-tweets//ajayc-Downloads-censored-tweets-raw_withheldtweets.json'\n",
    "# append_json_lines_to_existing(folder_path, existing_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
