{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze tweet authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>lang</th>\n",
       "      <th>tweet_type</th>\n",
       "      <th>source</th>\n",
       "      <th>source_link</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>linked_tweet</th>\n",
       "      <th>linked_user</th>\n",
       "      <th>sensitive</th>\n",
       "      <th>access</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>991691636999708672</td>\n",
       "      <td>755390902064078848</td>\n",
       "      <td>2018-05-02 14:51:25</td>\n",
       "      <td>tr</td>\n",
       "      <td>retweet</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>http://twitter.com/download/iphone</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.911024e+17</td>\n",
       "      <td>2.323138e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-05-02 14:51:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>991102360733745157</td>\n",
       "      <td>2323137780</td>\n",
       "      <td>2018-04-30 23:49:51</td>\n",
       "      <td>tr</td>\n",
       "      <td>tweet</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>http://twitter.com/download/android</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-05-02 14:51:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>991686033669488640</td>\n",
       "      <td>975074658331627522</td>\n",
       "      <td>2018-05-02 14:29:09</td>\n",
       "      <td>tr</td>\n",
       "      <td>reply</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>http://twitter.com/download/android</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.916786e+17</td>\n",
       "      <td>1.016064e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-05-02 14:52:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>991691846731649025</td>\n",
       "      <td>1016063701</td>\n",
       "      <td>2018-05-02 14:52:15</td>\n",
       "      <td>tr</td>\n",
       "      <td>quote</td>\n",
       "      <td>Twitter Lite</td>\n",
       "      <td>https://mobile.twitter.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.916860e+17</td>\n",
       "      <td>9.750747e+17</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-05-02 14:52:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>991692102588403713</td>\n",
       "      <td>825016420803235841</td>\n",
       "      <td>2018-05-02 14:53:16</td>\n",
       "      <td>und</td>\n",
       "      <td>retweet</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>http://twitter.com/download/iphone</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.913145e+17</td>\n",
       "      <td>8.691932e+17</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-05-02 14:53:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id           author_id           created_at lang  \\\n",
       "0  991691636999708672  755390902064078848  2018-05-02 14:51:25   tr   \n",
       "1  991102360733745157          2323137780  2018-04-30 23:49:51   tr   \n",
       "2  991686033669488640  975074658331627522  2018-05-02 14:29:09   tr   \n",
       "3  991691846731649025          1016063701  2018-05-02 14:52:15   tr   \n",
       "4  991692102588403713  825016420803235841  2018-05-02 14:53:16  und   \n",
       "\n",
       "  tweet_type               source                          source_link  \\\n",
       "0    retweet   Twitter for iPhone   http://twitter.com/download/iphone   \n",
       "1      tweet  Twitter for Android  http://twitter.com/download/android   \n",
       "2      reply  Twitter for Android  http://twitter.com/download/android   \n",
       "3      quote         Twitter Lite           https://mobile.twitter.com   \n",
       "4    retweet   Twitter for iPhone   http://twitter.com/download/iphone   \n",
       "\n",
       "   retweet_count  favorite_count  quote_count  reply_count  linked_tweet  \\\n",
       "0              0               0            0            0  9.911024e+17   \n",
       "1             65              45            3            5           NaN   \n",
       "2              0               0            0            0  9.916786e+17   \n",
       "3              0               0            0            0  9.916860e+17   \n",
       "4              0               0            0            0  9.913145e+17   \n",
       "\n",
       "    linked_user  sensitive               access  \n",
       "0  2.323138e+09      False  2018-05-02 14:51:25  \n",
       "1           NaN      False  2018-05-02 14:51:25  \n",
       "2  1.016064e+09      False  2018-05-02 14:52:15  \n",
       "3  9.750747e+17      False  2018-05-02 14:52:15  \n",
       "4  8.691932e+17      False  2018-05-02 14:53:16  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'parsed-files/write-folder/tweet_metadata.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect user ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[869193235918454786,\n",
       " 4764985268,\n",
       " 954124423,\n",
       " 2596413645,\n",
       " 738153522277945344,\n",
       " 92460378,\n",
       " 487834443,\n",
       " 919622839556337664,\n",
       " 1142312972,\n",
       " 214544700,\n",
       " 526110917,\n",
       " 248829087,\n",
       " 18118505,\n",
       " 455830743,\n",
       " 897619242,\n",
       " 25073877,\n",
       " 98996662,\n",
       " 847735496633536512,\n",
       " 365854454,\n",
       " 828115979758661632,\n",
       " 598468186,\n",
       " 870200407,\n",
       " 311118058,\n",
       " 2574890250,\n",
       " 723206253296640000]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_counts = data['author_id'].value_counts()\n",
    "\n",
    "# print(author_counts.head(int(len(author_counts) * 0.10)))   # prints top 10% of author_counts (should be 37)\n",
    "\n",
    "top_authors = list(author_counts.head(25).index)  # top 25 authors\n",
    "top_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_authors_ids = data['author_id'].unique()\n",
    "# unique_authors_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect date of tweet withheld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              author_id          created_at\n",
      "0              11325152 2018-05-02 21:47:25\n",
      "1              15738333 2018-05-02 15:24:04\n",
      "2              18118505 2018-04-29 00:24:24\n",
      "3              22153676 2018-05-02 09:01:47\n",
      "4              22703645 2018-05-02 00:49:32\n",
      "..                  ...                 ...\n",
      "369  987394916719431680 2018-05-02 20:03:07\n",
      "370  987748224437030917 2018-05-02 17:10:28\n",
      "371  987752531009916929 2018-05-02 18:04:22\n",
      "372  990276638997991424 2018-05-02 20:36:04\n",
      "373  991369146976931840 2018-05-02 22:26:29\n",
      "\n",
      "[374 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Ensure the 'created_at' column is in datetime format\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "\n",
    "# Group by 'author_id' and get the earliest date in 'created_at' column\n",
    "earliest_dates = data.groupby('author_id')['created_at'].min().reset_index()\n",
    "\n",
    "# Display the earliest dates for each author_id\n",
    "print(earliest_dates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              author_id          created_at\n",
      "2              18118505 2018-04-29 00:24:24\n",
      "6              25073877 2018-05-02 13:23:17\n",
      "23             92460378 2018-05-02 14:29:29\n",
      "25             98996662 2018-05-02 18:49:17\n",
      "35            214544700 2018-05-02 15:18:53\n",
      "43            248829087 2018-05-01 21:36:52\n",
      "53            311118058 2018-05-01 17:35:16\n",
      "64            365854454 2018-05-02 17:00:00\n",
      "73            455830743 2018-04-29 16:39:21\n",
      "75            487834443 2018-04-20 09:40:46\n",
      "78            526110917 2018-05-01 21:39:22\n",
      "88            598468186 2018-05-02 17:47:31\n",
      "99            870200407 2018-05-02 19:17:18\n",
      "100           897619242 2018-05-02 15:41:50\n",
      "102           954124423 2017-11-10 23:10:50\n",
      "113          1142312972 2018-05-02 07:36:11\n",
      "165          2574890250 2018-05-02 11:50:34\n",
      "166          2596413645 2018-05-02 02:57:41\n",
      "220          4764985268 2016-03-23 12:42:38\n",
      "227  723206253296640000 2018-05-01 09:32:46\n",
      "231  738153522277945344 2018-05-02 00:36:58\n",
      "271  828115979758661632 2018-05-02 19:43:41\n",
      "287  847735496633536512 2018-05-01 21:45:29\n",
      "298  869193235918454786 2018-04-07 19:30:56\n",
      "318  919622839556337664 2018-05-02 19:56:42\n"
     ]
    }
   ],
   "source": [
    "filtered_earliest_dates = earliest_dates[earliest_dates['author_id'].isin(top_authors)] \n",
    "print(filtered_earliest_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{18118505: '2018-04-29 00:24:24',\n",
       " 25073877: '2018-05-02 13:23:17',\n",
       " 92460378: '2018-05-02 14:29:29',\n",
       " 98996662: '2018-05-02 18:49:17',\n",
       " 214544700: '2018-05-02 15:18:53',\n",
       " 248829087: '2018-05-01 21:36:52',\n",
       " 311118058: '2018-05-01 17:35:16',\n",
       " 365854454: '2018-05-02 17:00:00',\n",
       " 455830743: '2018-04-29 16:39:21',\n",
       " 487834443: '2018-04-20 09:40:46',\n",
       " 526110917: '2018-05-01 21:39:22',\n",
       " 598468186: '2018-05-02 17:47:31',\n",
       " 870200407: '2018-05-02 19:17:18',\n",
       " 897619242: '2018-05-02 15:41:50',\n",
       " 954124423: '2017-11-10 23:10:50',\n",
       " 1142312972: '2018-05-02 07:36:11',\n",
       " 2574890250: '2018-05-02 11:50:34',\n",
       " 2596413645: '2018-05-02 02:57:41',\n",
       " 4764985268: '2016-03-23 12:42:38',\n",
       " 723206253296640000: '2018-05-01 09:32:46',\n",
       " 738153522277945344: '2018-05-02 00:36:58',\n",
       " 828115979758661632: '2018-05-02 19:43:41',\n",
       " 847735496633536512: '2018-05-01 21:45:29',\n",
       " 869193235918454786: '2018-04-07 19:30:56',\n",
       " 919622839556337664: '2018-05-02 19:56:42'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict = filtered_earliest_dates.set_index('author_id')['created_at'].dt.strftime('%Y-%m-%d %h:%m:%s').to_dict()\n",
    "\n",
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"18118505\": \"2018-04-29 00:24:24\",\n",
      "    \"25073877\": \"2018-05-02 13:23:17\",\n",
      "    \"92460378\": \"2018-05-02 14:29:29\",\n",
      "    \"98996662\": \"2018-05-02 18:49:17\",\n",
      "    \"214544700\": \"2018-05-02 15:18:53\",\n",
      "    \"248829087\": \"2018-05-01 21:36:52\",\n",
      "    \"311118058\": \"2018-05-01 17:35:16\",\n",
      "    \"365854454\": \"2018-05-02 17:00:00\",\n",
      "    \"455830743\": \"2018-04-29 16:39:21\",\n",
      "    \"487834443\": \"2018-04-20 09:40:46\",\n",
      "    \"526110917\": \"2018-05-01 21:39:22\",\n",
      "    \"598468186\": \"2018-05-02 17:47:31\",\n",
      "    \"870200407\": \"2018-05-02 19:17:18\",\n",
      "    \"897619242\": \"2018-05-02 15:41:50\",\n",
      "    \"954124423\": \"2017-11-10 23:10:50\",\n",
      "    \"1142312972\": \"2018-05-02 07:36:11\",\n",
      "    \"2574890250\": \"2018-05-02 11:50:34\",\n",
      "    \"2596413645\": \"2018-05-02 02:57:41\",\n",
      "    \"4764985268\": \"2016-03-23 12:42:38\",\n",
      "    \"723206253296640000\": \"2018-05-01 09:32:46\",\n",
      "    \"738153522277945344\": \"2018-05-02 00:36:58\",\n",
      "    \"828115979758661632\": \"2018-05-02 19:43:41\",\n",
      "    \"847735496633536512\": \"2018-05-01 21:45:29\",\n",
      "    \"869193235918454786\": \"2018-04-07 19:30:56\",\n",
      "    \"919622839556337664\": \"2018-05-02 19:56:42\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json_data = json.dumps(result_dict, indent=4)\n",
    "\n",
    "print(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go through raw data (what we ran the 1-mining.py script on) to see if user activity declined before and after the date they had a tweet withheld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import bz2\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "data_folder = 'path_to_your_bz2_files'  # Path to the folder with .bz2 files\n",
    "withholding_info_file = 'withholding_info.json'  # Path to the JSON file with author withholding info\n",
    "\n",
    "with open(withholding_info_file, 'r') as f:\n",
    "    withholding_dates = {author_id: datetime.strptime(date, \"%Y-%m-%d\") for author_id, date in json.load(f).items()}\n",
    "\n",
    "tweet_counts = {author_id: {'before': 0, 'after': 0} for author_id in withholding_dates}\n",
    "\n",
    "def parse_tweet_line(line, tweet_counts):\n",
    "    try:\n",
    "        tweet = json.loads(line)\n",
    "    except json.JSONDecodeError:\n",
    "        return\n",
    "\n",
    "    author_id = tweet.get('user', {}).get('id_str')\n",
    "    created_at = tweet.get('created_at')\n",
    "\n",
    "    if not author_id or author_id not in withholding_dates or not created_at:\n",
    "        return\n",
    "\n",
    "    # Convert tweet timestamp to datetime\n",
    "    tweet_date = datetime.strptime(created_at, \"%a %b %d %H:%M:%S +0000 %Y\")\n",
    "\n",
    "    # Compare tweet date with withholding date\n",
    "    if tweet_date < withholding_dates[author_id]:\n",
    "        tweet_counts[author_id]['before'] += 1\n",
    "    else:\n",
    "        tweet_counts[author_id]['after'] += 1\n",
    "\n",
    "def process_file(file_path, tweet_counts):\n",
    "    with bz2.open(file_path, 'rt') as f:\n",
    "        for line in f:\n",
    "            parse_tweet_line(line, tweet_counts)\n",
    "\n",
    "def main():\n",
    "    # Iterate over all .bz2 files \n",
    "    for root, _, files in os.walk(data_folder):\n",
    "        for file in files:\n",
    "            if file.endswith('.bz2'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                process_file(file_path, tweet_counts)\n",
    "\n",
    "    for author_id, counts in tweet_counts.items():\n",
    "        print(f\"Author {author_id}: {counts['before']} tweets before, {counts['after']} tweets after withholding date.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
