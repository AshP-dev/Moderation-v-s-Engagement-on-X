{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze tweet authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>lang</th>\n",
       "      <th>tweet_type</th>\n",
       "      <th>source</th>\n",
       "      <th>source_link</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>linked_tweet</th>\n",
       "      <th>linked_user</th>\n",
       "      <th>sensitive</th>\n",
       "      <th>access</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>991691636999708672</td>\n",
       "      <td>755390902064078848</td>\n",
       "      <td>2018-05-02 14:51:25</td>\n",
       "      <td>tr</td>\n",
       "      <td>retweet</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>http://twitter.com/download/iphone</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.911024e+17</td>\n",
       "      <td>2.323138e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-05-02 14:51:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>991102360733745157</td>\n",
       "      <td>2323137780</td>\n",
       "      <td>2018-04-30 23:49:51</td>\n",
       "      <td>tr</td>\n",
       "      <td>tweet</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>http://twitter.com/download/android</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-05-02 14:51:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>991686033669488640</td>\n",
       "      <td>975074658331627522</td>\n",
       "      <td>2018-05-02 14:29:09</td>\n",
       "      <td>tr</td>\n",
       "      <td>reply</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>http://twitter.com/download/android</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.916786e+17</td>\n",
       "      <td>1.016064e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-05-02 14:52:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>991691846731649025</td>\n",
       "      <td>1016063701</td>\n",
       "      <td>2018-05-02 14:52:15</td>\n",
       "      <td>tr</td>\n",
       "      <td>quote</td>\n",
       "      <td>Twitter Lite</td>\n",
       "      <td>https://mobile.twitter.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.916860e+17</td>\n",
       "      <td>9.750747e+17</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-05-02 14:52:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>991692102588403713</td>\n",
       "      <td>825016420803235841</td>\n",
       "      <td>2018-05-02 14:53:16</td>\n",
       "      <td>und</td>\n",
       "      <td>retweet</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>http://twitter.com/download/iphone</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.913145e+17</td>\n",
       "      <td>8.691932e+17</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-05-02 14:53:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id           author_id           created_at lang  \\\n",
       "0  991691636999708672  755390902064078848  2018-05-02 14:51:25   tr   \n",
       "1  991102360733745157          2323137780  2018-04-30 23:49:51   tr   \n",
       "2  991686033669488640  975074658331627522  2018-05-02 14:29:09   tr   \n",
       "3  991691846731649025          1016063701  2018-05-02 14:52:15   tr   \n",
       "4  991692102588403713  825016420803235841  2018-05-02 14:53:16  und   \n",
       "\n",
       "  tweet_type               source                          source_link  \\\n",
       "0    retweet   Twitter for iPhone   http://twitter.com/download/iphone   \n",
       "1      tweet  Twitter for Android  http://twitter.com/download/android   \n",
       "2      reply  Twitter for Android  http://twitter.com/download/android   \n",
       "3      quote         Twitter Lite           https://mobile.twitter.com   \n",
       "4    retweet   Twitter for iPhone   http://twitter.com/download/iphone   \n",
       "\n",
       "   retweet_count  favorite_count  quote_count  reply_count  linked_tweet  \\\n",
       "0              0               0            0            0  9.911024e+17   \n",
       "1             65              45            3            5           NaN   \n",
       "2              0               0            0            0  9.916786e+17   \n",
       "3              0               0            0            0  9.916860e+17   \n",
       "4              0               0            0            0  9.913145e+17   \n",
       "\n",
       "    linked_user  sensitive               access  \n",
       "0  2.323138e+09      False  2018-05-02 14:51:25  \n",
       "1           NaN      False  2018-05-02 14:51:25  \n",
       "2  1.016064e+09      False  2018-05-02 14:52:15  \n",
       "3  9.750747e+17      False  2018-05-02 14:52:15  \n",
       "4  8.691932e+17      False  2018-05-02 14:53:16  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '/Users/ashwatthaphatak/Desktop/NCSU/CSC_555/Project/data/write-folder/tweet_metadata.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect user ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[869193235918454786,\n",
       " 4764985268,\n",
       " 954124423,\n",
       " 2596413645,\n",
       " 738153522277945344,\n",
       " 92460378,\n",
       " 919622839556337664,\n",
       " 487834443,\n",
       " 1142312972,\n",
       " 214544700,\n",
       " 248829087,\n",
       " 526110917,\n",
       " 18118505,\n",
       " 455830743,\n",
       " 897619242,\n",
       " 311118058,\n",
       " 825682538416971778,\n",
       " 828115979758661632,\n",
       " 243726128,\n",
       " 326003773,\n",
       " 25073877,\n",
       " 870200407,\n",
       " 365854454,\n",
       " 2252893931,\n",
       " 98996662]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_counts = data['author_id'].value_counts()\n",
    "\n",
    "# print(author_counts.head(int(len(author_counts) * 0.10)))   # prints top 10% of author_counts (should be 37)\n",
    "\n",
    "top_authors = list(author_counts.head(25).index)  # top 25 authors\n",
    "top_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_authors_ids = data['author_id'].unique()\n",
    "# unique_authors_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect date of tweet withheld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              author_id          created_at\n",
      "0              11325152 2018-05-02 21:47:25\n",
      "1              15738333 2018-05-02 15:24:04\n",
      "2              18118505 2018-04-29 00:24:24\n",
      "3              22153676 2018-05-02 09:01:47\n",
      "4              22703645 2018-05-02 00:49:32\n",
      "..                  ...                 ...\n",
      "369  987394916719431680 2018-05-02 20:03:07\n",
      "370  987748224437030917 2018-05-02 17:10:28\n",
      "371  987752531009916929 2018-05-02 18:04:22\n",
      "372  990276638997991424 2018-05-02 20:36:04\n",
      "373  991369146976931840 2018-05-02 22:26:29\n",
      "\n",
      "[374 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Ensure the 'created_at' column is in datetime format\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "\n",
    "# Group by 'author_id' and get the earliest date in 'created_at' column\n",
    "earliest_dates = data.groupby('author_id')['created_at'].min().reset_index()\n",
    "\n",
    "# Display the earliest dates for each author_id\n",
    "print(earliest_dates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              author_id          created_at\n",
      "2              18118505 2018-04-29 00:24:24\n",
      "6              25073877 2018-05-02 13:23:17\n",
      "23             92460378 2018-05-02 14:29:29\n",
      "25             98996662 2018-05-02 18:49:17\n",
      "35            214544700 2018-05-02 15:18:53\n",
      "42            243726128 2018-05-02 19:04:23\n",
      "43            248829087 2018-05-01 21:36:52\n",
      "53            311118058 2018-05-01 17:35:16\n",
      "57            326003773 2018-05-02 16:00:04\n",
      "64            365854454 2018-05-02 17:00:00\n",
      "73            455830743 2018-04-29 16:39:21\n",
      "75            487834443 2018-04-20 09:40:46\n",
      "78            526110917 2018-05-01 21:39:22\n",
      "99            870200407 2018-05-02 19:17:18\n",
      "100           897619242 2018-05-02 15:41:50\n",
      "102           954124423 2017-11-10 23:10:50\n",
      "113          1142312972 2018-05-02 07:36:11\n",
      "143          2252893931 2018-05-01 03:00:46\n",
      "166          2596413645 2018-05-02 02:57:41\n",
      "220          4764985268 2016-03-23 12:42:38\n",
      "231  738153522277945344 2018-05-02 00:36:58\n",
      "269  825682538416971778 2018-05-01 20:56:46\n",
      "271  828115979758661632 2018-05-02 19:43:41\n",
      "298  869193235918454786 2018-04-07 19:30:56\n",
      "318  919622839556337664 2018-05-02 19:56:42\n"
     ]
    }
   ],
   "source": [
    "filtered_earliest_dates = earliest_dates[earliest_dates['author_id'].isin(top_authors)] \n",
    "print(filtered_earliest_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{18118505: '2018-04-29 Apr:04:1524975864',\n",
       " 25073877: '2018-05-02 May:05:1525281797',\n",
       " 92460378: '2018-05-02 May:05:1525285769',\n",
       " 98996662: '2018-05-02 May:05:1525301357',\n",
       " 214544700: '2018-05-02 May:05:1525288733',\n",
       " 243726128: '2018-05-02 May:05:1525302263',\n",
       " 248829087: '2018-05-01 May:05:1525225012',\n",
       " 311118058: '2018-05-01 May:05:1525210516',\n",
       " 326003773: '2018-05-02 May:05:1525291204',\n",
       " 365854454: '2018-05-02 May:05:1525294800',\n",
       " 455830743: '2018-04-29 Apr:04:1525034361',\n",
       " 487834443: '2018-04-20 Apr:04:1524231646',\n",
       " 526110917: '2018-05-01 May:05:1525225162',\n",
       " 870200407: '2018-05-02 May:05:1525303038',\n",
       " 897619242: '2018-05-02 May:05:1525290110',\n",
       " 954124423: '2017-11-10 Nov:11:1510373450',\n",
       " 1142312972: '2018-05-02 May:05:1525260971',\n",
       " 2252893931: '2018-05-01 May:05:1525158046',\n",
       " 2596413645: '2018-05-02 May:05:1525244261',\n",
       " 4764985268: '2016-03-23 Mar:03:1458751358',\n",
       " 738153522277945344: '2018-05-02 May:05:1525235818',\n",
       " 825682538416971778: '2018-05-01 May:05:1525222606',\n",
       " 828115979758661632: '2018-05-02 May:05:1525304621',\n",
       " 869193235918454786: '2018-04-07 Apr:04:1523143856',\n",
       " 919622839556337664: '2018-05-02 May:05:1525305402'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict = filtered_earliest_dates.set_index('author_id')['created_at'].dt.strftime('%Y-%m-%d %h:%m:%s').to_dict()\n",
    "\n",
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"18118505\": \"2018-04-29 Apr:04:1524975864\",\n",
      "    \"25073877\": \"2018-05-02 May:05:1525281797\",\n",
      "    \"92460378\": \"2018-05-02 May:05:1525285769\",\n",
      "    \"98996662\": \"2018-05-02 May:05:1525301357\",\n",
      "    \"214544700\": \"2018-05-02 May:05:1525288733\",\n",
      "    \"243726128\": \"2018-05-02 May:05:1525302263\",\n",
      "    \"248829087\": \"2018-05-01 May:05:1525225012\",\n",
      "    \"311118058\": \"2018-05-01 May:05:1525210516\",\n",
      "    \"326003773\": \"2018-05-02 May:05:1525291204\",\n",
      "    \"365854454\": \"2018-05-02 May:05:1525294800\",\n",
      "    \"455830743\": \"2018-04-29 Apr:04:1525034361\",\n",
      "    \"487834443\": \"2018-04-20 Apr:04:1524231646\",\n",
      "    \"526110917\": \"2018-05-01 May:05:1525225162\",\n",
      "    \"870200407\": \"2018-05-02 May:05:1525303038\",\n",
      "    \"897619242\": \"2018-05-02 May:05:1525290110\",\n",
      "    \"954124423\": \"2017-11-10 Nov:11:1510373450\",\n",
      "    \"1142312972\": \"2018-05-02 May:05:1525260971\",\n",
      "    \"2252893931\": \"2018-05-01 May:05:1525158046\",\n",
      "    \"2596413645\": \"2018-05-02 May:05:1525244261\",\n",
      "    \"4764985268\": \"2016-03-23 Mar:03:1458751358\",\n",
      "    \"738153522277945344\": \"2018-05-02 May:05:1525235818\",\n",
      "    \"825682538416971778\": \"2018-05-01 May:05:1525222606\",\n",
      "    \"828115979758661632\": \"2018-05-02 May:05:1525304621\",\n",
      "    \"869193235918454786\": \"2018-04-07 Apr:04:1523143856\",\n",
      "    \"919622839556337664\": \"2018-05-02 May:05:1525305402\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json_data = json.dumps(result_dict, indent=4)\n",
    "\n",
    "print(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go through raw data (what we ran the 1-mining.py script on) to see if user activity declined before and after the date they had a tweet withheld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'withholding_info.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m data_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath_to_your_bz2_files\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Path to the folder with .bz2 files\u001b[39;00m\n\u001b[1;32m      7\u001b[0m withholding_info_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwithholding_info.json\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Path to the JSON file with author withholding info\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwithholding_info_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     10\u001b[0m     withholding_dates \u001b[38;5;241m=\u001b[39m {author_id: datetime\u001b[38;5;241m.\u001b[39mstrptime(date, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m author_id, date \u001b[38;5;129;01min\u001b[39;00m json\u001b[38;5;241m.\u001b[39mload(f)\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     12\u001b[0m tweet_counts \u001b[38;5;241m=\u001b[39m {author_id: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m} \u001b[38;5;28;01mfor\u001b[39;00m author_id \u001b[38;5;129;01min\u001b[39;00m withholding_dates}\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'withholding_info.json'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import bz2\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "data_folder = 'path_to_your_bz2_files'  # Path to the folder with .bz2 files\n",
    "withholding_info_file = 'withholding_info.json'  # Path to the JSON file with author withholding info\n",
    "\n",
    "with open(withholding_info_file, 'r') as f:\n",
    "    withholding_dates = {author_id: datetime.strptime(date, \"%Y-%m-%d\") for author_id, date in json.load(f).items()}\n",
    "\n",
    "tweet_counts = {author_id: {'before': 0, 'after': 0} for author_id in withholding_dates}\n",
    "\n",
    "def parse_tweet_line(line, tweet_counts):\n",
    "    try:\n",
    "        tweet = json.loads(line)\n",
    "    except json.JSONDecodeError:\n",
    "        return\n",
    "\n",
    "    author_id = tweet.get('user', {}).get('id_str')\n",
    "    created_at = tweet.get('created_at')\n",
    "\n",
    "    if not author_id or author_id not in withholding_dates or not created_at:\n",
    "        return\n",
    "\n",
    "    # Convert tweet timestamp to datetime\n",
    "    tweet_date = datetime.strptime(created_at, \"%a %b %d %H:%M:%S +0000 %Y\")\n",
    "\n",
    "    # Compare tweet date with withholding date\n",
    "    if tweet_date < withholding_dates[author_id]:\n",
    "        tweet_counts[author_id]['before'] += 1\n",
    "    else:\n",
    "        tweet_counts[author_id]['after'] += 1\n",
    "\n",
    "def process_file(file_path, tweet_counts):\n",
    "    with bz2.open(file_path, 'rt') as f:\n",
    "        for line in f:\n",
    "            parse_tweet_line(line, tweet_counts)\n",
    "\n",
    "def main():\n",
    "    # Iterate over all .bz2 files \n",
    "    for root, _, files in os.walk(data_folder):\n",
    "        for file in files:\n",
    "            if file.endswith('.bz2'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                process_file(file_path, tweet_counts)\n",
    "\n",
    "    for author_id, counts in tweet_counts.items():\n",
    "        print(f\"Author {author_id}: {counts['before']} tweets before, {counts['after']} tweets after withholding date.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
